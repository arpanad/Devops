1. ETCD Backup and Restore
==========================

To list the pods running in kube-system namespace

controlplane $ kubectl -n kube-system get pod
NAME                                       READY   STATUS    RESTARTS   AGE
calico-kube-controllers-5f94594857-smxtv   1/1     Running   3          4d12h
canal-2t87j                                2/2     Running   0          15m
canal-sttmm                                2/2     Running   0          15m
coredns-68dc769db8-6cwk7                   1/1     Running   0          4d12h
coredns-68dc769db8-9h8gn                   1/1     Running   0          4d12h
etcd-controlplane                          1/1     Running   0          4d12h
kube-apiserver-controlplane                1/1     Running   2          4d12h
kube-controller-manager-controlplane       1/1     Running   2          4d12h
kube-proxy-ldwqn                           1/1     Running   0          4d12h
kube-proxy-pftdf                           1/1     Running   0          4d12h
kube-scheduler-controlplane                1/1     Running   2          4d12h
controlplane $


To describe the etcd-controlplane pod

controlplane $ kubectl -n kube-system describe pod etcd-controlplane
Name:                 etcd-controlplane
Namespace:            kube-system
Priority:             2000001000
Priority Class Name:  system-node-critical
Node:                 controlplane/172.30.1.2
Start Time:           Tue, 11 Apr 2023 13:47:00 +0000
Labels:               component=etcd
                      tier=control-plane
Annotations:          kubeadm.kubernetes.io/etcd.advertise-client-urls: https://172.30.1.2:2379
                      kubernetes.io/config.hash: b148b4402415a8256914b3120a64c814
                      kubernetes.io/config.mirror: b148b4402415a8256914b3120a64c814
                      kubernetes.io/config.seen: 2023-04-11T13:48:25.081329796Z
                      kubernetes.io/config.source: file
Status:               Running
IP:                   172.30.1.2
IPs:
  IP:           172.30.1.2
Controlled By:  Node/controlplane
Containers:
  etcd:
    Container ID:  containerd://70b4244f257a3075a40a94dae479cd3d9f69bb3069a7e07c1ab2b8019f2fad70
    Image:         registry.k8s.io/etcd:3.5.6-0
    Image ID:      registry.k8s.io/etcd@sha256:dd75ec974b0a2a6f6bb47001ba09207976e625db898d1b16735528c009cb171c
    Port:          <none>
    Host Port:     <none>
    Command:
      etcd
      --advertise-client-urls=https://172.30.1.2:2379
      --cert-file=/etc/kubernetes/pki/etcd/server.crt
      --client-cert-auth=true
      --data-dir=/var/lib/etcd
      --experimental-initial-corrupt-check=true
      --experimental-watch-progress-notify-interval=5s
      --initial-advertise-peer-urls=https://172.30.1.2:2380
      --initial-cluster=controlplane=https://172.30.1.2:2380
      --key-file=/etc/kubernetes/pki/etcd/server.key
      --listen-client-urls=https://127.0.0.1:2379,https://172.30.1.2:2379
      --listen-metrics-urls=http://127.0.0.1:2381
      --listen-peer-urls=https://172.30.1.2:2380
      --name=controlplane
      --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt
      --peer-client-cert-auth=true
      --peer-key-file=/etc/kubernetes/pki/etcd/peer.key
      --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
      --snapshot-count=10000
      --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
    State:          Running
      Started:      Tue, 11 Apr 2023 13:48:50 +0000
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:        25m
      memory:     100Mi
    Liveness:     http-get http://127.0.0.1:2381/health%3Fexclude=NOSPACE&serializable=true delay=10s timeout=15s period=10s #success=1 #failure=8
    Startup:      http-get http://127.0.0.1:2381/health%3Fserializable=false delay=10s timeout=15s period=10s #success=1 #failure=24
    Environment:  <none>
    Mounts:
      /etc/kubernetes/pki/etcd from etcd-certs (rw)
      /var/lib/etcd from etcd-data (rw)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  etcd-certs:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/kubernetes/pki/etcd
    HostPathType:  DirectoryOrCreate
  etcd-data:
    Type:          HostPath (bare host directory volume)
    Path:          /var/lib/etcd
    HostPathType:  DirectoryOrCreate
QoS Class:         Burstable
Node-Selectors:    <none>
Tolerations:       :NoExecute op=Exists
Events:
  Type    Reason   Age    From     Message
  ----    ------   ----   ----     -------
  Normal  Pulled   4d13h  kubelet  Container image "registry.k8s.io/etcd:3.5.6-0" already present on machine
  Normal  Created  4d13h  kubelet  Created container etcd
  Normal  Started  4d13h  kubelet  Started container etcd
controlplane $


Create 2 deployments:

controlplane $ kubectl create deployment blue --image=nginx:1.20.1 --replicas=3
deployment.apps/blue created
controlplane $ 
controlplane $ 
controlplane $ kubectl create deployment red --image=nginx:1.20.1 --replicas=3
deployment.apps/red created
controlplane $


To find the deployments:

controlplane $ kubectl get deployments.app
NAME   READY   UP-TO-DATE   AVAILABLE   AGE
blue   3/3     3            3           39s
red    3/3     3            3           31s
controlplane $



To take the backup of the etcd:

Refer the documentation and get the template and add the values

(Template)
ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
  --cacert=<trusted-ca-file> --cert=<cert-file> --key=<key-file> \
  snapshot save <backup-file-location>
  
 
(After adding values) 
controlplane $ ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
>   --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key \
>   snapshot save /opt/snapshot-pre-boot.db
{"level":"info","ts":1681614571.5468812,"caller":"snapshot/v3_snapshot.go:68","msg":"created temporary db file","path":"/opt/snapshot-pre-boot.db.part"}
{"level":"info","ts":1681614571.564495,"logger":"client","caller":"v3/maintenance.go:211","msg":"opened snapshot stream; downloading"}
{"level":"info","ts":1681614571.5647285,"caller":"snapshot/v3_snapshot.go:76","msg":"fetching snapshot","endpoint":"https://127.0.0.1:2379"}
{"level":"info","ts":1681614571.7481716,"logger":"client","caller":"v3/maintenance.go:219","msg":"completed snapshot read; closing"}
{"level":"info","ts":1681614571.7536092,"caller":"snapshot/v3_snapshot.go:91","msg":"fetched snapshot","endpoint":"https://127.0.0.1:2379","size":"6.2 MB","took":"now"}
{"level":"info","ts":1681614571.7539244,"caller":"snapshot/v3_snapshot.go:100","msg":"saved","path":"/opt/snapshot-pre-boot.db"}
Snapshot saved at /opt/snapshot-pre-boot.db
controlplane $ 
controlplane $


To restore the etcd backup taken:

take the template and modify
ETCDCTL_API=3 etcdctl --endpoints 10.2.0.9:2379 snapshot restore snapshotdb          --  template

ETCDCTL_API=3 etcdctl --data-dir=/var/lib/etcd-backup snapshot restore /opt/snapshot-pre-boot.db

controlplane $ ETCDCTL_API=3 etcdctl --data-dir=/var/lib/etcd-backup snapshot restore /opt/snapshot-pre-boot.db
Deprecated: Use `etcdutl snapshot restore` instead.

2023-04-16T03:23:43Z    info    snapshot/v3_snapshot.go:251     restoring snapshot      {"path": "/opt/snapshot-pre-boot.db", "wal-dir": "/var/lib/etcd-backup/member/wal", "data-dir": "/var/lib/etcd-backup", "snap-dir": "/var/lib/etcd-backup/member/snap", "stack": "go.etcd.io/etcd/etcdutl/v3/snapshot.(*v3Manager).Restore\n\t/tmp/etcd-release-3.5.0/etcd/release/etcd/etcdutl/snapshot/v3_snapshot.go:257\ngo.etcd.io/etcd/etcdutl/v3/etcdutl.SnapshotRestoreCommandFunc\n\t/tmp/etcd-release-3.5.0/etcd/release/etcd/etcdutl/etcdutl/snapshot_command.go:147\ngo.etcd.io/etcd/etcdctl/v3/ctlv3/command.snapshotRestoreCommandFunc\n\t/tmp/etcd-release-3.5.0/etcd/release/etcd/etcdctl/ctlv3/command/snapshot_command.go:128\ngithub.com/spf13/cobra.(*Command).execute\n\t/home/remote/sbatsche/.gvm/pkgsets/go1.16.3/global/pkg/mod/github.com/spf13/cobra@v1.1.3/command.go:856\ngithub.com/spf13/cobra.(*Command).ExecuteC\n\t/home/remote/sbatsche/.gvm/pkgsets/go1.16.3/global/pkg/mod/github.com/spf13/cobra@v1.1.3/command.go:960\ngithub.com/spf13/cobra.(*Command).Execute\n\t/home/remote/sbatsche/.gvm/pkgsets/go1.16.3/global/pkg/mod/github.com/spf13/cobra@v1.1.3/command.go:897\ngo.etcd.io/etcd/etcdctl/v3/ctlv3.Start\n\t/tmp/etcd-release-3.5.0/etcd/release/etcd/etcdctl/ctlv3/ctl.go:107\ngo.etcd.io/etcd/etcdctl/v3/ctlv3.MustStart\n\t/tmp/etcd-release-3.5.0/etcd/release/etcd/etcdctl/ctlv3/ctl.go:111\nmain.main\n\t/tmp/etcd-release-3.5.0/etcd/release/etcd/etcdctl/main.go:59\nruntime.main\n\t/home/remote/sbatsche/.gvm/gos/go1.16.3/src/runtime/proc.go:225"}
2023-04-16T03:23:43Z    info    membership/store.go:119 Trimming membership information from the backend...
2023-04-16T03:23:43Z    info    membership/cluster.go:393       added member    {"cluster-id": "cdf818194e3a8c32", "local-member-id": "0", "added-peer-id": "8e9e05c52164694d", "added-peer-peer-urls": ["http://localhost:2380"]}
2023-04-16T03:23:43Z    info    snapshot/v3_snapshot.go:272     restored snapshot       {"path": "/opt/snapshot-pre-boot.db", "wal-dir": "/var/lib/etcd-backup/member/wal", "data-dir": "/var/lib/etcd-backup", "snap-dir": "/var/lib/etcd-backup/member/snap"}
controlplane $








Modify the /etc/kubernetes/manifests/etcd.yaml file 

(old)
  volumes:
  - hostPath:
      path: /etc/kubernetes/pki/etcd
      type: DirectoryOrCreate
    name: etcd-certs
  - hostPath:
      path: /var/lib/etcd
      type: DirectoryOrCreate
    name: etcd-data
status: {}


(new)
  volumes:
  - hostPath:
      path: /etc/kubernetes/pki/etcd
      type: DirectoryOrCreate
    name: etcd-certs
  - hostPath:
      path: /var/lib/etcd-backup
      type: DirectoryOrCreate
    name: etcd-data
status: {}


To verify:

controlplane $ docker ps | grep etcd
controlplane $ 
controlplane $ 
controlplane $ kubectl get deployments.apps 
NAME   READY   UP-TO-DATE   AVAILABLE   AGE
blue   3/3     3            3           38m
red    3/3     3            3           37m
controlplane $ 


controlplane $ kubectl get pod
NAME                    READY   STATUS    RESTARTS   AGE
blue-5cdb7b98b7-72c6j   1/1     Running   0          38m
blue-5cdb7b98b7-d6q6d   1/1     Running   0          38m
blue-5cdb7b98b7-ljfw8   1/1     Running   0          38m
red-7dd785ff8b-2jdnl    1/1     Running   0          38m
red-7dd785ff8b-7zqcp    1/1     Running   0          38m
red-7dd785ff8b-mf8lk    1/1     Running   0          38m
controlplane $



4. Simple Pod Creation ... Imperative and Declarative way
==========================================================


Creating pod Declarative way by writing the file:

Create a yaml file  with the contents as below
controlplane $ vi definition.yaml 
controlplane $ cat definition.yaml
apiVersion: v1
kind: Pod
metadata:
  name: static-web
  labels:
    env: prod
spec:
  containers:
    - name: web
      image: nginx


Use the below command to create the pod :

controlplane $ kubectl apply -f definition.yaml 
pod/static-web created


To list the pods thats created :

controlplane $ kubectl get pod
NAME         READY   STATUS    RESTARTS   AGE
static-web   1/1     Running   0          2m29s


Details/Description of pod :

controlplane $ kubectl describe pod static-web 
Name:             static-web
Namespace:        default
Priority:         0
Service Account:  default
Node:             node01/172.30.2.2
Start Time:       Fri, 07 Apr 2023 14:33:13 +0000
Labels:           env=prod
Annotations:      cni.projectcalico.org/containerID: 2b12160150966f4e51ea3e57c0069574ed011b1b481f39713742a62884d3366a
                  cni.projectcalico.org/podIP: 192.168.1.3/32
                  cni.projectcalico.org/podIPs: 192.168.1.3/32
Status:           Running
IP:               192.168.1.3
IPs:
  IP:  192.168.1.3
Containers:
  web:
    Container ID:   containerd://3c206f238d364b4881db23f0580b02ad791c66ef13c1262029e608d390cc644e
    Image:          nginx
    Image ID:       docker.io/library/nginx@sha256:2ab30d6ac53580a6db8b657abf0f68d75360ff5cc1670a85acb5bd85ba1b19c0
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Fri, 07 Apr 2023 14:33:19 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-mspb7 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  kube-api-access-mspb7:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age    From               Message
  ----    ------     ----   ----               -------
  Normal  Scheduled  7m44s  default-scheduler  Successfully assigned default/static-web to node01
  Normal  Pulling    7m44s  kubelet            Pulling image "nginx"
  Normal  Pulled     7m39s  kubelet            Successfully pulled image "nginx" in 5.253366637s (5.253370595s including waiting)
  Normal  Created    7m39s  kubelet            Created container web
  Normal  Started    7m39s  kubelet            Started container web
controlplane $



To list details of pod with wide option :

controlplane $ kubectl get pod static-web -o wide
NAME         READY   STATUS    RESTARTS   AGE     IP            NODE     NOMINATED NODE   READINESS GATES
static-web   1/1     Running   0          8m50s   192.168.1.3   node01   <none>           <none>
controlplane $


To list the pods with label filter:
controlplane $ kubectl get pod -l env=prod
NAME         READY   STATUS    RESTARTS   AGE
static-web   1/1     Running   0          10m
controlplane $


To find the image details of pod:

controlplane $ kubectl describe pod static-web | grep -i Image
    Image:          nginx
    Image ID:       docker.io/library/nginx@sha256:2ab30d6ac53580a6db8b657abf0f68d75360ff5cc1670a85acb5bd85ba1b19c0
  Normal  Pulling    11m   kubelet            Pulling image "nginx"
  Normal  Pulled     11m   kubelet            Successfully pulled image "nginx" in 5.253366637s (5.253370595s including waiting)
controlplane $ kubectl describe pod static-web | grep Image
    Image:          nginx
    Image ID:       docker.io/library/nginx@sha256:2ab30d6ac53580a6db8b657abf0f68d75360ff5cc1670a85acb5bd85ba1b19c0
controlplane $ 


Imperative way of creating a pod:

controlplane $ kubectl run simple-pod --image=nginx
pod/simple-pod created
controlplane $ kubectl get pod
NAME         READY   STATUS    RESTARTS   AGE
simple-pod   1/1     Running   0          19s
static-web   1/1     Running   0          15m
controlplane $


Declarative way of creating a pod by creating a file:

controlplane $ kubectl run simple-pod1 --image=nginx dry-run=client -o yaml
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: "2023-04-07T14:53:11Z"
  labels:
    run: simple-pod1
  name: simple-pod1
  namespace: default
  resourceVersion: "4380"
  uid: 3f2e20d1-fcec-4def-a082-0d0046a6d080
spec:
  containers:
  - args:
    - dry-run=client
    image: nginx
    imagePullPolicy: Always
    name: simple-pod1
    resources: {}
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-drshh
      readOnly: true
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  preemptionPolicy: PreemptLowerPriority
  priority: 0
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: default
  serviceAccountName: default
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  volumes:
  - name: kube-api-access-drshh
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
status:
  phase: Pending
  qosClass: BestEffort
controlplane $



To delete a pod:

controlplane $ kubectl delete pod simple-pod1  
pod "simple-pod1" deleted
controlplane $








5.Replica Sets:
===============

To create deployment:

controlplane $ kubectl create deployment rs-simple --image=nginx --replicas=3 --dry-run=client -o yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: rs-simple
  name: rs-simple
spec:
  replicas: 3
  selector:
    matchLabels:
      app: rs-simple
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: rs-simple
    spec:
      containers:
      - image: nginx
        name: nginx
        resources: {}
status: {}
controlplane $


Create the below file:
controlplane $ cat rs.yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  labels:
    app: rs-simple
  name: rs-simple
spec:
  replicas: 3
  selector:
    matchLabels:
      app: rs-simple
  template:
    metadata:
      labels:
        app: rs-simple
    spec:
      containers:
      - image: nginx
        name: nginx
controlplane $


Create the replica set using the below command:

controlplane $ kubectl apply -f rs.yaml 
replicaset.apps/rs-simple created


To find the details of the replica set and pods

controlplane $ kubectl get rs
NAME        DESIRED   CURRENT   READY   AGE
rs-simple   3         3         2       14s
controlplane $ 

controlplane $ kubectl get pod
NAME              READY   STATUS              RESTARTS   AGE
rs-simple-dvv2l   0/1     ContainerCreating   0          111s
rs-simple-lvx9j   1/1     Running             0          111s
rs-simple-q4cnp   1/1     Running             0          111s
controlplane $


To delete a pod from replica set:
controlplane $ kubectl delete pod rs-simple-q4cnp
pod "rs-simple-q4cnp" deleted
controlplane $

for the deleetd pod, new pod gets created:

controlplane $ kubectl get pod
NAME              READY   STATUS              RESTARTS   AGE
rs-simple-dvv2l   0/1     ContainerCreating   0          3m29s
rs-simple-lvx9j   1/1     Running             0          3m29s
rs-simple-qdflr   1/1     Running 


To edit the version of rs :

controlplane $ kubectl edit rs rs-simple 
replicaset.apps/rs-simple edited
controlplane $ 
controlplane $ 
controlplane $ kubectl describe rs rs-simple | grep -i Image
    Image:        nginx:1.20.1
controlplane $ 
controlplane $ 
controlplane $ kubectl get po   
NAME              READY   STATUS              RESTARTS   AGE
rs-simple-dvv2l   0/1     ContainerCreating   0          7m25s
rs-simple-lvx9j   1/1     Running             0          7m25s
rs-simple-qdflr   1/1     Running             0          4m36s
controlplane $ 
controlplane $ 
controlplane $ kubectl describe pod rs-simple-qdflr | grep -i Image
    Image:          nginx
    Image ID:       docker.io/library/nginx@sha256:2ab30d6ac53580a6db8b657abf0f68d75360ff5cc1670a85acb5bd85ba1b19c0
  Normal  Pulling    4m57s  kubelet            Pulling image "nginx"
  Normal  Pulled     4m57s  kubelet            Successfully pulled image "nginx" in 508.558031ms (508.562293ms including waiting)
controlplane $


Note :It wont work so we have to create new replica set.

To delete the replica set:
controlplane $ kubectl delete rs rs-simple 
replicaset.apps "rs-simple" deleted
controlplane $ 
controlplane $ 
controlplane $ kubectl get rs
No resources found in default namespace.
controlplane $ 
controlplane $ kubectl get pod
NAME              READY   STATUS        RESTARTS   AGE
rs-simple-dvv2l   0/1     Terminating   0          9m55s
controlplane $

Note : we cannot delete pods that belong to replica set. we have to delete the replica set to delete the pods.





6. DEPLOYMENTS:
===============

To create a deployment :

controlplane $ kubectl create deployment web --image=nginx:1.20.1
deployment.apps/web created


To get the deployment details:

controlplane $ kubectl get deployment
NAME   READY   UP-TO-DATE   AVAILABLE   AGE
web    1/1     1            1           11s


To get the replic set details:

controlplane $ kubectl get rs        
NAME             DESIRED   CURRENT   READY   AGE
web-779f9cc4cc   1         1         1       80s


To get the pod details: 
controlplane $ kubectl get pod
NAME                   READY   STATUS    RESTARTS   AGE
web-779f9cc4cc-nd78m   1/1     Running   0          83s
controlplane $

To describe the deployment and to fetch the image:

controlplane $ kubectl describe deployments.apps web | grep -i image 
    Image:        nginx:1.20.1
controlplane $


To delete the pod and the new replacement is observed in the deployment:

controlplane $ kubectl delete pod web-779f9cc4cc-nd78m
pod "web-779f9cc4cc-nd78m" deleted
controlplane $ 
controlplane $ 
controlplane $ kubectl get pod                        
NAME                   READY   STATUS    RESTARTS   AGE
web-779f9cc4cc-hhbjn   1/1     Running   0          7s
controlplane $


To scale the deployments from 1 replica to 4:

controlplane $ kubectl scale deployment web --replicas=4
deployment.apps/web scaled
controlplane $

After scaling:
controlplane $ kubectl get pod
NAME                   READY   STATUS    RESTARTS   AGE
web-779f9cc4cc-5b2q2   1/1     Running   0          40s
web-779f9cc4cc-9nffc   1/1     Running   0          40s
web-779f9cc4cc-hhbjn   1/1     Running   0          107s
web-779f9cc4cc-kstgn   1/1     Running   0          40s
controlplane $


controlplane $ kubectl get deployments.apps 
NAME   READY   UP-TO-DATE   AVAILABLE   AGE
web    4/4     4            4           6m34s
controlplane $


To describe the deployment:

controlplane $ kubectl describe deployments.apps web
Name:                   web
Namespace:              default
CreationTimestamp:      Sat, 08 Apr 2023 02:18:36 +0000
Labels:                 app=web
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=web
Replicas:               4 desired | 4 updated | 4 total | 4 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=web
  Containers:
   nginx:
    Image:        nginx:1.20.1
    Port:         <none>
    Host Port:    <none>
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Progressing    True    NewReplicaSetAvailable
  Available      True    MinimumReplicasAvailable
OldReplicaSets:  <none>
NewReplicaSet:   web-779f9cc4cc (4/4 replicas created)
Events:
  Type    Reason             Age    From                   Message
  ----    ------             ----   ----                   -------
  Normal  ScalingReplicaSet  7m12s  deployment-controller  Scaled up replica set web-779f9cc4cc to 1
  Normal  ScalingReplicaSet  116s   deployment-controller  Scaled up replica set web-779f9cc4cc to 4 from 1
controlplane $



To change the image of the pods in the deployment:

controlplane $ kubectl set image deployment web nginx=nginx:1.21.1 --record
Flag --record has been deprecated, --record will be removed in the future
deployment.apps/web image updated
controlplane $

controlplane $ kubectl get rs         
NAME             DESIRED   CURRENT   READY   AGE
web-779f9cc4cc   0         0         0       10m
web-77b7dc689d   4         4         4       26s
controlplane $

To verify the changed image:

controlplane $ kubectl describe deployments.apps web | grep -i image
                        kubernetes.io/change-cause: kubectl set image deployment web nginx=nginx:1.21.1 --record=true
    Image:        nginx:1.21.1
controlplane $


To check the history of the deployments:

controlplane $ kubectl describe deployments.apps web | grep -i image
                        kubernetes.io/change-cause: kubectl set image deployment web nginx=nginx:1.21.1 --record=true
    Image:        nginx:1.21.1
controlplane $ 
controlplane $ 
controlplane $ 
controlplane $ 
controlplane $ kubectl describe deployments.apps web
Name:                   web
Namespace:              default
CreationTimestamp:      Sat, 08 Apr 2023 02:18:36 +0000
Labels:                 app=web
Annotations:            deployment.kubernetes.io/revision: 2
                        kubernetes.io/change-cause: kubectl set image deployment web nginx=nginx:1.21.1 --record=true
Selector:               app=web
Replicas:               4 desired | 4 updated | 4 total | 4 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=web
  Containers:
   nginx:
    Image:        nginx:1.21.1
    Port:         <none>
    Host Port:    <none>
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  <none>
NewReplicaSet:   web-77b7dc689d (4/4 replicas created)
Events:
  Type    Reason             Age    From                   Message
  ----    ------             ----   ----                   -------
  Normal  ScalingReplicaSet  12m    deployment-controller  Scaled up replica set web-779f9cc4cc to 1
  Normal  ScalingReplicaSet  6m55s  deployment-controller  Scaled up replica set web-779f9cc4cc to 4 from 1
  Normal  ScalingReplicaSet  2m31s  deployment-controller  Scaled up replica set web-77b7dc689d to 1
  Normal  ScalingReplicaSet  2m31s  deployment-controller  Scaled down replica set web-779f9cc4cc to 3 from 4
  Normal  ScalingReplicaSet  2m31s  deployment-controller  Scaled up replica set web-77b7dc689d to 2 from 1
  Normal  ScalingReplicaSet  2m23s  deployment-controller  Scaled down replica set web-779f9cc4cc to 2 from 3
  Normal  ScalingReplicaSet  2m23s  deployment-controller  Scaled up replica set web-77b7dc689d to 3 from 2
  Normal  ScalingReplicaSet  2m22s  deployment-controller  Scaled down replica set web-779f9cc4cc to 1 from 2
  Normal  ScalingReplicaSet  2m22s  deployment-controller  Scaled up replica set web-77b7dc689d to 4 from 3
  Normal  ScalingReplicaSet  2m21s  deployment-controller  (combined from similar events): Scaled down replica set web-779f9cc4cc to 0 from 1
  
  
To check the rollback history:

controlplane $ kubectl rollout history deployment web
deployment.apps/web 
REVISION  CHANGE-CAUSE
1         <none>
2         kubectl set image deployment web nginx=nginx:1.21.1 --record=true

controlplane $



To go back to previous revision :

controlplane $ kubectl rollout undo deployment web
deployment.apps/web rolled back
controlplane $ 
controlplane $ 
controlplane $ kubectl get rs
NAME             DESIRED   CURRENT   READY   AGE
web-779f9cc4cc   4         4         4       17m
web-77b7dc689d   0         0         0       7m59s
controlplane $ 
controlplane $ 
controlplane $ kubectl get deployments.apps 
NAME   READY   UP-TO-DATE   AVAILABLE   AGE
web    4/4     4            4           17m
controlplane $ 
controlplane $ 
controlplane $ kubectl describe deployments.apps web | grep -i image
    Image:        nginx:1.20.1
controlplane $


Note: the image is reverted back to old one and the old replica set is having all the pods




7. KUBERNETES LABEL AND SELECTOR:
=================================

* Label is a key value pair thats attached to an object like pod/deployment/replica set
* It is used to identify the objects with respect to any project or codeline.
* It can be added at anytime i.e.; during creation or later


Create 2 pods:

controlplane $ kubectl run web-dev image --image=nginx
pod/web-dev created
controlplane $ kubectl run db-dev image --image=nginx
pod/db-dev created
controlplane $

To get all the pods with their labels:

controlplane $ kubectl get pod --show-labels
NAME      READY   STATUS             RESTARTS      AGE   LABELS
db-dev    0/1     CrashLoopBackOff   1 (8s ago)    10s   run=db-dev
web-dev   0/1     CrashLoopBackOff   1 (11s ago)   17s   run=web-dev
controlplane $


To lable the pods:

controlplane $ kubectl label pod db-dev env=dev name=db
pod/db-dev labeled
controlplane $ 
controlplane $ 
controlplane $ kubectl label pod web-dev env=dev name=web
pod/web-dev labeled
controlplane $

controlplane $ kubectl get pod --show-labels
NAME      READY   STATUS             RESTARTS      AGE     LABELS
db-dev    0/1     CrashLoopBackOff   4 (44s ago)   2m9s    env=dev,name=db,run=db-dev
web-dev   0/1     CrashLoopBackOff   4 (36s ago)   2m16s   env=dev,name=web,run=web-dev
controlplane $



Create new pods:
controlplane $ kubectl run web-prod --image=nginx
pod/web-prod created
controlplane $


controlplane $ kubectl run db-prod --image=nginx --dry-run=client -o yaml
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: db-prod
  name: db-prod
spec:
  containers:
  - image: nginx
    name: db-prod
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
controlplane $

controlplane $ cat db-prod.yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    env: prod
    name: db
  name: db-prod
spec:
  containers:
  - image: nginx
    name: db-prod
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
controlplane $

controlplane $ kubectl apply -f db-prod.yaml 
pod/db-prod created

controlplane $ kubectl get pod --show-labels
NAME       READY   STATUS             RESTARTS        AGE     LABELS
db-dev     0/1     CrashLoopBackOff   7 (2m51s ago)   13m     env=dev,name=db,run=db-dev
db-prod    1/1     Running            0               66s     env=prod,name=db
web-dev    0/1     CrashLoopBackOff   7 (2m48s ago)   13m     env=dev,name=web,run=web-dev
web-prod   1/1     Running            0               9m11s   run=web-prod
controlplane $ 
controlplane $ 
controlplane $ kubectl label pod web-prod env=prod name=web
pod/web-prod labeled
controlplane $ 
controlplane $ kubectl get pod --show-labels
NAME       READY   STATUS             RESTARTS        AGE     LABELS
db-dev     0/1     CrashLoopBackOff   7 (3m29s ago)   14m     env=dev,name=db,run=db-dev
db-prod    1/1     Running            0               104s    env=prod,name=db
web-dev    0/1     CrashLoopBackOff   7 (3m26s ago)   14m     env=dev,name=web,run=web-dev
web-prod   1/1     Running            0               9m49s   env=prod,name=web,run=web-prod
controlplane $ 



controlplane $ kubectl get pod -l env=prod  
NAME       READY   STATUS    RESTARTS   AGE
db-prod    1/1     Running   0          2m22s
web-prod   1/1     Running   0          10m
controlplane $


controlplane $ kubectl get pod -l env=prod,name=web
NAME       READY   STATUS    RESTARTS   AGE
web-prod   1/1     Running   0          10m
controlplane $ 


To remove env lable from web-prod pod:

controlplane $ kubectl label pod web-prod env-
pod/web-prod unlabeled


controlplane $ kubectl get pod --show-labels
NAME       READY   STATUS             RESTARTS      AGE     LABELS
db-dev     0/1     CrashLoopBackOff   8 (80s ago)   17m     env=dev,name=db,run=db-dev
db-prod    1/1     Running            0             4m42s   env=prod,name=db
web-dev    0/1     CrashLoopBackOff   8 (72s ago)   17m     env=dev,name=web,run=web-dev
web-prod   1/1     Running            0             12m     name=web,run=web-prod
controlplane $



8. Taint and Tolerations
=========================

Taint : to restrict the pod on which node it has to run
Toleration is available in the description file
Taint at node
Toleration is at pod


To list the nodes:
controlplane $ kubectl get node
NAME           STATUS   ROLES           AGE   VERSION
controlplane   Ready    control-plane   43d   v1.26.1
node01         Ready    <none>          43d   v1.26.1
controlplane $

To get the taint on the nodes:
controlplane $ kubectl describe node controlplane | grep -i taint
Taints:             <none>
controlplane $

controlplane $ kubectl describe node node01 | grep -i taint
Taints:             <none>
controlplane 


Create a pod and check on which node:

controlplane $ kubectl run test-pod --image=nginx
pod/test-pod created
controlplane $ 
controlplane $ 


controlplane $ 
controlplane $ kubectl get pod -o wide
NAME       READY   STATUS    RESTARTS   AGE   IP            NODE     NOMINATED NODE   READINESS GATES
test-pod   1/1     Running   0          12s   192.168.1.3   node01   <none>           <none>
controlplane $ 


To taint a node:
controlplane $ kubectl taint node node01 key1=value1:NoSchedule
node/node01 tainted
controlplane $

controlplane $ kubectl describe nodes node01 | grep -i Taints
Taints:             key1=value1:NoSchedule
controlplane $

Note: When taint is applied on all the nodes as noSchedule and a pod is created then the pod state will be as Pending. And no toleration is applied on the pod.

As taint is applied to node01 the pod2 is running on controlplane :

controlplane $ kubectl run test-pod2 --image=nginx
pod/test-pod2 created
controlplane $ 
controlplane $ 
controlplane $ kubectl get pod -o wide
NAME        READY   STATUS    RESTARTS   AGE     IP            NODE           NOMINATED NODE   READINESS GATES
test-pod    1/1     Running   0          28m     192.168.1.3   node01         <none>           <none>
test-pod2   1/1     Running   0          10s     192.168.0.8   controlplane   <none>           <none>

To add toleration to the pod:

controlplane $ kubectl run test-pod3 --image=nginx --dry-run=client -o yaml
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: test-pod3
  name: test-pod3
spec:
  containers:
  - image: nginx
    name: test-pod3
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
controlplane $


create a file pod.yaml and add the below content:
controlplane $ cat pod.yaml 
apiVersion: v1
kind: Pod
metadata:
  labels:
    run: test-pod3
  name: test-pod3
spec:
  containers:
  - image: nginx
    name: test-pod3
  tolerations:
  - key: "key1"
    operator: "Equal"
    value: "value1"
    effect: "NoSchedule"
	
Create the pod:
controlplane $ kubectl apply -f pod.yaml 
pod/test-pod3 created
 as we tainted 
controlplane $ kubectl get pod -o wide
NAME        READY   STATUS    RESTARTS   AGE    IP            NODE     NOMINATED NODE   READINESS GATES
test-pod    1/1     Running   0          27m    192.168.1.3   node01   <none>           <none>
test-pod3   1/1     Running   0          103s   192.168.1.4   node01   <none>           <none>
controlplane $


To remove taint:

controlplane $ kubectl taint node node01 key1=value1:NoSchedule-
node/node01 untainted
controlplane 

controlplane $ 
controlplane $ kubectl describe nodes node01 | grep -i taint
Taints:             <none>
controlplane $ 

Note:
Once the taint is removed, the pod that was in pending state with toleration to a node then that pod status changes to Running.



9.NAMESAPACES:
==============

controlplane $ kubectl get pod
No resources found in default namespace.

 
controlplane $ kubectl get deployments
No resources found in default namespace.


controlplane $ kubectl get node
NAME           STATUS   ROLES           AGE   VERSION
controlplane   Ready    control-plane   17d   v1.26.1
node01         Ready    <none>          17d   v1.26.1


controlplane $ kubectl get namespaces 
NAME                 STATUS   AGE
default              Active   17d
kube-node-lease      Active   17d
kube-public          Active   17d
kube-system          Active   17d
local-path-storage   Active   17d


Create a pod and get the pods in default namespace:

controlplane $ kubectl run test --image=nginx 
pod/test created
controlplane $ 
controlplane $ 
controlplane $ kubectl get pod 
NAME   READY   STATUS    RESTARTS   AGE
test   1/1     Running   0          7s
controlplane $ 
controlplane $ 
controlplane $ kubectl get pod -n default
NAME   READY   STATUS    RESTARTS   AGE
test   1/1     Running   0          25s
controlplane $ 


To create a new namespace and list it:
controlplane $ kubectl create ns pod-ns
namespace/pod-ns created
controlplane $ 
controlplane $ 
controlplane $ 
controlplane $ kubectl get ns
NAME                 STATUS   AGE
default              Active   17d
kube-node-lease      Active   17d
kube-public          Active   17d
kube-system          Active   17d
local-path-storage   Active   17d
pod-ns               Active   31s
controlplane 




To create pod in the namespace thats created and to list the pod in that namespace:
controlplane $ kubectl run test-pod --image=nginx -n pod-ns
pod/test-pod created


controlplane $ kubectl get pod  
NAME   READY   STATUS    RESTARTS   AGE
test   1/1     Running   0          4m43s


controlplane $ kubectl get pod -n pod-ns
NAME       READY   STATUS    RESTARTS   AGE
test-pod   1/1     Running   0          22s
controlplane $


To list all the objects in the default and created namespace:

controlplane $ kubectl get all
NAME       READY   STATUS    RESTARTS   AGE
pod/test   1/1     Running   0          6m24s

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   17d
controlplane $ 
controlplane $ 
controlplane $ 
controlplane $ 
controlplane $ 
controlplane $ kubectl get all -n pod-ns
NAME           READY   STATUS    RESTARTS   AGE
pod/test-pod   1/1     Running   0          2m13s
controlplane $





To list all the resources that are dependant on namespace:

controlplane $ kubectl api-resources --namespaced=true 
NAME                        SHORTNAMES   APIVERSION                     NAMESPACED   KIND
bindings                                 v1                             true         Binding
configmaps                  cm           v1                             true         ConfigMap
endpoints                   ep           v1                             true         Endpoints
events                      ev           v1                             true         Event
limitranges                 limits       v1                             true         LimitRange
persistentvolumeclaims      pvc          v1                             true         PersistentVolumeClaim
pods                        po           v1                             true         Pod
podtemplates                             v1                             true         PodTemplate
replicationcontrollers      rc           v1                             true         ReplicationController
resourcequotas              quota        v1                             true         ResourceQuota
secrets                                  v1                             true         Secret
serviceaccounts             sa           v1                             true         ServiceAccount
services                    svc          v1                             true         Service
controllerrevisions                      apps/v1                        true         ControllerRevision
daemonsets                  ds           apps/v1                        true         DaemonSet
deployments                 deploy       apps/v1                        true         Deployment
replicasets                 rs           apps/v1                        true         ReplicaSet
statefulsets                sts          apps/v1                        true         StatefulSet
localsubjectaccessreviews                authorization.k8s.io/v1        true         LocalSubjectAccessReview
horizontalpodautoscalers    hpa          autoscaling/v2                 true         HorizontalPodAutoscaler
cronjobs                    cj           batch/v1                       true         CronJob
jobs                                     batch/v1                       true         Job
leases                                   coordination.k8s.io/v1         true         Lease
networkpolicies                          crd.projectcalico.org/v1       true         NetworkPolicy
networksets                              crd.projectcalico.org/v1       true         NetworkSet
endpointslices                           discovery.k8s.io/v1            true         EndpointSlice
events                      ev           events.k8s.io/v1               true         Event
ingresses                   ing          networking.k8s.io/v1           true         Ingress
networkpolicies             netpol       networking.k8s.io/v1           true         NetworkPolicy
poddisruptionbudgets        pdb          policy/v1                      true         PodDisruptionBudget
rolebindings                             rbac.authorization.k8s.io/v1   true         RoleBinding
roles                                    rbac.authorization.k8s.io/v1   true         Role
csistoragecapacities                     storage.k8s.io/v1              true         CSIStorageCapacity
controlplane $


To list all the resources that are not dependant on namespace:

controlplane $ kubectl api-resources --namespaced=false
NAME                              SHORTNAMES   APIVERSION                             NAMESPACED   KIND
componentstatuses                 cs           v1                                     false        ComponentStatus
namespaces                        ns           v1                                     false        Namespace
nodes                             no           v1                                     false        Node
persistentvolumes                 pv           v1                                     false        PersistentVolume
mutatingwebhookconfigurations                  admissionregistration.k8s.io/v1        false        MutatingWebhookConfiguration
validatingwebhookconfigurations                admissionregistration.k8s.io/v1        false        ValidatingWebhookConfiguration
customresourcedefinitions         crd,crds     apiextensions.k8s.io/v1                false        CustomResourceDefinition
apiservices                                    apiregistration.k8s.io/v1              false        APIService
tokenreviews                                   authentication.k8s.io/v1               false        TokenReview
selfsubjectaccessreviews                       authorization.k8s.io/v1                false        SelfSubjectAccessReview
selfsubjectrulesreviews                        authorization.k8s.io/v1                false        SelfSubjectRulesReview
subjectaccessreviews                           authorization.k8s.io/v1                false        SubjectAccessReview
certificatesigningrequests        csr          certificates.k8s.io/v1                 false        CertificateSigningRequest
bgpconfigurations                              crd.projectcalico.org/v1               false        BGPConfiguration
bgppeers                                       crd.projectcalico.org/v1               false        BGPPeer
blockaffinities                                crd.projectcalico.org/v1               false        BlockAffinity
caliconodestatuses                             crd.projectcalico.org/v1               false        CalicoNodeStatus
clusterinformations                            crd.projectcalico.org/v1               false        ClusterInformation
felixconfigurations                            crd.projectcalico.org/v1               false        FelixConfiguration
globalnetworkpolicies                          crd.projectcalico.org/v1               false        GlobalNetworkPolicy
globalnetworksets                              crd.projectcalico.org/v1               false        GlobalNetworkSet
hostendpoints                                  crd.projectcalico.org/v1               false        HostEndpoint
ipamblocks                                     crd.projectcalico.org/v1               false        IPAMBlock
ipamconfigs                                    crd.projectcalico.org/v1               false        IPAMConfig
ipamhandles                                    crd.projectcalico.org/v1               false        IPAMHandle
ippools                                        crd.projectcalico.org/v1               false        IPPool
ipreservations                                 crd.projectcalico.org/v1               false        IPReservation
kubecontrollersconfigurations                  crd.projectcalico.org/v1               false        KubeControllersConfiguration
flowschemas                                    flowcontrol.apiserver.k8s.io/v1beta3   false        FlowSchema
prioritylevelconfigurations                    flowcontrol.apiserver.k8s.io/v1beta3   false        PriorityLevelConfiguration
ingressclasses                                 networking.k8s.io/v1                   false        IngressClass
runtimeclasses                                 node.k8s.io/v1                         false        RuntimeClass
clusterrolebindings                            rbac.authorization.k8s.io/v1           false        ClusterRoleBinding
clusterroles                                   rbac.authorization.k8s.io/v1           false        ClusterRole
priorityclasses                   pc           scheduling.k8s.io/v1                   false        PriorityClass
csidrivers                                     storage.k8s.io/v1                      false        CSIDriver
csinodes                                       storage.k8s.io/v1                      false        CSINode
storageclasses                    sc           storage.k8s.io/v1                      false        StorageClass
volumeattachments                              storage.k8s.io/v1                      false        VolumeAttachment
controlplane $




To switch to a namespace:

controlplane $ kubectl config set-context --current --namespace=pod-ns
Context "kubernetes-admin@kubernetes" modified.



controlplane $ kubectl get pod
NAME       READY   STATUS    RESTARTS   AGE
test-pod   1/1     Running   0          9m25s
controlplane $


(now in pod-ns namespace)
controlplane $ kubectl get pod -n default
NAME   READY   STATUS    RESTARTS   AGE
test   1/1     Running   0          14m
controlplane $ 



11. CONFIG MAPS:
================

To create config map:
controlplane $ kubectl create cm myconfigmap --from-literal=app.memory=1000
configmap/myconfigmap created
controlplane $


To get the config maps:

controlplane $ kubectl get configmaps 
NAME               DATA   AGE
kube-root-ca.crt   1      17d
myconfigmap        1      21s
controlplane $


To get a single config map in yaml format:

controlplane $ kubectl get configmaps myconfigmap -o yaml
apiVersion: v1
data:
  app.memory: "1000"
kind: ConfigMap
metadata:
  creationTimestamp: "2023-04-29T00:26:15Z"
  name: myconfigmap
  namespace: default
  resourceVersion: "2694"
  uid: a4afdc66-020a-4a3d-b7f3-d8becbffacb6
controlplane $ 



Create a pod using the below yaml file:

controlplane $ cat pod.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: mypod-cm
spec:
  containers:
  - name: mypod
    image: nginx
    volumeMounts:
    - name: mycm-volume
      mountPath: "/etc/myvolume"
      readOnly: true
  volumes:
  - name: mycm-volume
    configMap:
      name: myconfigmap
controlplane $ 

controlplane $ kubectl apply -f pod.yaml
pod/mypod-cm created
controlplane $


controlplane $ kubectl get pod
NAME       READY   STATUS    RESTARTS   AGE
mypod-cm   1/1     Running   0          92s
controlplane $



controlplane $ kubectl get pod
NAME       READY   STATUS    RESTARTS   AGE
mypod-cm   1/1     Running   0          92s
controlplane $ 
controlplane $ 
controlplane $ 
controlplane $ 
controlplane $ kubectl describe pod mypod-cm 
Name:             mypod-cm
Namespace:        default
Priority:         0
Service Account:  default
Node:             node01/172.30.2.2
Start Time:       Sat, 29 Apr 2023 00:40:48 +0000
Labels:           <none>
Annotations:      cni.projectcalico.org/containerID: 19a4c58fa2ae295e7bccae888790d4dc2fbb4fa22762b5e290717704c3acc181
                  cni.projectcalico.org/podIP: 192.168.1.3/32
                  cni.projectcalico.org/podIPs: 192.168.1.3/32
Status:           Running
IP:               192.168.1.3
IPs:
  IP:  192.168.1.3
Containers:
  mypod:
    Container ID:   containerd://886f1bccf44e193b515f225e95c6ba21ad48f70247a462407e506ef76689b708
    Image:          nginx
    Image ID:       docker.io/library/nginx@sha256:63b44e8ddb83d5dd8020327c1f40436e37a6fffd3ef2498a6204df23be6e7e94
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Sat, 29 Apr 2023 00:40:54 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /etc/myvolume from mycm-volume (ro)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-kkdzq (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  mycm-volume:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      myconfigmap
    Optional:  false
  kube-api-access-kkdzq:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age    From               Message
  ----    ------     ----   ----               -------
  Normal  Scheduled  2m14s  default-scheduler  Successfully assigned default/mypod-cm to node01
  Normal  Pulling    2m13s  kubelet            Pulling image "nginx"
  Normal  Pulled     2m8s   kubelet            Successfully pulled image "nginx" in 4.841774961s (4.8417793s including waiting)
  Normal  Created    2m8s   kubelet            Created container mypod
  Normal  Started    2m8s   kubelet            Started container mypod
  
  
  
To login to the pod and check the volumeMount:
controlplane $ kubectl exec -it mypod-cm bash
kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.
root@mypod-cm:/# 
root@mypod-cm:/# 
root@mypod-cm:/# 
root@mypod-cm:/# 
root@mypod-cm:/# 
root@mypod-cm:/# cd /etc/myvolume/
root@mypod-cm:/etc/myvolume# ls
app.memory
root@mypod-cm:/etc/myvolume# 
root@mypod-cm:/etc/myvolume# 
root@mypod-cm:/etc/myvolume# cat app.memory 
1000





To delete the configMap thats created:

controlplane $ kubectl get configmaps 
NAME               DATA   AGE
kube-root-ca.crt   1      17d
myconfigmap        1      21m
controlplane $ 
controlplane $ 
controlplane $ 
controlplane $ kubectl delete configmaps myconfigmap 
configmap "myconfigmap" deleted
controlplane $ 
controlplane $ 
controlplane $ kubectl get configmaps 
NAME               DATA   AGE
kube-root-ca.crt   1      17d
controlplane $ 


To create a config map using a file:

controlplane $ cat app.properties 
app.environments=prod
app.memory=16000
app.url=prod.env.url
controlplane $

controlplane $ kubectl create configmap myconfigmap --from-file=app.properties 
configmap/myconfigmap created

controlplane $ kubectl get configmaps myconfigmap -o yaml
apiVersion: v1
data:
  app.properties: |
    app.environments=prod
    app.memory=16000
    app.url=prod.env.url
kind: ConfigMap
metadata:
  creationTimestamp: "2023-04-29T00:51:26Z"
  name: myconfigmap
  namespace: default
  resourceVersion: "4826"
  uid: f4fb4a40-2d9e-4642-81d1-87009b0a5357
controlplane $




controlplane $ kubectl get pod
NAME       READY   STATUS    RESTARTS   AGE
mypod-cm   1/1     Running   0          12m



controlplane $ kubectl exec -it mypod-cm bash
kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.
root@mypod-cm:/# 
root@mypod-cm:/# 
root@mypod-cm:/# cd /etc/myvolume/
root@mypod-cm:/etc/myvolume# 
root@mypod-cm:/etc/myvolume# ls
app.properties
root@mypod-cm:/etc/myvolume# 
root@mypod-cm:/etc/myvolume# 
root@mypod-cm:/etc/myvolume# cat app.properties 
app.environments=prod
app.memory=16000
app.url=prod.env.url
root@mypod-cm:/etc/myvolume# 


(Changes made in config map is updated in the file thats avilable in the pod)



12. SECRETS:
============

To get the secrets:

controlplane $ kubectl get secrets
No resources found in default namespace.
controlplane $



To conevert a password to base64:

controlplane $ openssl enc -base64 <<< 'secret123'
c2VjcmV0MTIzCg==
controlplane $



To convert base64 to normal text:

controlplane $ openssl enc -base64 -d <<< 'c2VjcmV0MTIzCg=='
secret123
controlplane $ 


Create a secret and verify:

controlplane $ kubectl create secret generic myfirstsecret --from-literal=db_pass=secret123
secret/myfirstsecret created
controlplane $ 
controlplane $ 
controlplane $ kubectl get secrets
NAME            TYPE     DATA   AGE
myfirstsecret   Opaque   1      6s
controlplane $



Describe the secret:

controlplane $ kubectl describe secrets myfirstsecret 
Name:         myfirstsecret
Namespace:    default
Labels:       <none>
Annotations:  <none>

Type:  Opaque

Data
====
db_pass:  9 bytes


Get the secret in yaml format:

controlplane $ kubectl get secrets myfirstsecret -o yaml 
apiVersion: v1
data:
  db_pass: c2VjcmV0MTIz
kind: Secret
metadata:
  creationTimestamp: "2023-04-29T02:54:22Z"
  name: myfirstsecret
  namespace: default
  resourceVersion: "4092"
  uid: 4b5047b7-3fc2-4c2a-b01d-32519d98a6b1
type: Opaque
controlplane $ 


Decode the password obtained and verify if its same as used while creating the secret:

controlplane $ openssl enc -base64 -d <<< c2VjcmV0MTIz
secret123





To create a secret using yaml file where the password is in base64:

controlplane $ vi sec-secret.yaml
controlplane $ 
controlplane $ 
controlplane $ cat sec-secret.yaml 
apiVersion: v1
kind: Secret
metadata:
  name: mysecondsecret
type: Opaque
data:
  db_pass: c2VjcmV0MTIzCg==
controlplane $ 

controlplane $ kubectl apply -f sec-secret.yaml 
secret/mysecondsecret created

To get the secret just created:

controlplane $ kubectl get secrets mysecondsecret 
NAME             TYPE     DATA   AGE
mysecondsecret   Opaque   1      57s
controlplane $ 
controlplane $ 
controlplane $ kubectl get secrets mysecondsecret -o yaml
apiVersion: v1
data:
  db_pass: c2VjcmV0MTIzCg==
kind: Secret
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","data":{"db_pass":"c2VjcmV0MTIzCg=="},"kind":"Secret","metadata":{"annotations":{},"name":"mysecondsecret","namespace":"default"},"type":"Opaque"}
  creationTimestamp: "2023-04-29T03:03:55Z"
  name: mysecondsecret
  namespace: default
  resourceVersion: "4891"
  uid: 62f1b437-d349-4def-9181-e0ef7ebbb4ff
type: Opaque
controlplane $


Get the db pass and decode it:

controlplane $ openssl enc -base64 -d <<< 'c2VjcmV0MTIzCg=='
secret123



Creating secret using yaml file with password as normal text:

controlplane $ vi third-secret.yaml 
controlplane $ 
controlplane $ 
controlplane $ cat third-secret.yaml 
apiVersion: v1
kind: Secret
metadata:
  name: mythirdsecret
stringData:
  db_pass: secret123
controlplane $


controlplane $ kubectl apply -f third-secret.yaml 
secret/mythirdsecret created
controlplane $ 


controlplane $ kubectl get secrets 
NAME             TYPE     DATA   AGE
myfirstsecret    Opaque   1      15m
mysecondsecret   Opaque   1      5m48s
mythirdsecret    Opaque   1      25s
controlplane $ 



To create pod volume in pod and to place the password in that volume path :

controlplane $ cat pod-volume.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: mysecretpod
spec:
  containers:
  - name: mysecretpod
    image: nginx
    volumeMounts:
    - name: sec-volume
      mountPath: "/etc/volume"
      readOnly: true
  volumes:
  - name: sec-volume
    secret:
      secretName: myfirstsecret
controlplane $ 

controlplane $ kubectl apply -f pod-volume.yaml 
pod/mysecretpod created
controlplane $


root@mysecretpod:/etc/volume# pwd
/etc/volume

root@mysecretpod:/etc/volume# ls
db_pass

root@mysecretpod:/etc/volume# cat db_pass 
secret123


To use env variable:

ontrolplane $ cat pod-env.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: secret-env-pod
spec:
  containers:
  - name: mycontainer
    image: nginx
    env:
      - name: DB_PASS
        valueFrom:
          secretKeyRef:
            name: myfirstsecret
            key: db_pass
  restartPolicy: Never
controlplane $ 


Login to the pod and get the pass by using env variable:

controlplane $ kubectl exec -it secret-env-pod bash
kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.
root@secret-env-pod:/# 
root@secret-env-pod:/# 
root@secret-env-pod:/# 
root@secret-env-pod:/# echo $DB_PASS
secret123
root@secret-env-pod:/#
